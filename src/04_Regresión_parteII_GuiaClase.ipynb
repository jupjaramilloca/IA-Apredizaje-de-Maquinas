{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ZSqZKG_mDuXDBMFpvy2KCQXVsuFubEtW","timestamp":1714075480103}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Practica 4: Regresión Parte 2\n","**Elaborado por: Luis Fernando Becerra,  BEDA Aprendizaje de Máquinas 2024-1S **"],"metadata":{"id":"I6Pj3HvlEj39"}},{"cell_type":"markdown","source":["Vamos a probar dos modelos avanzados de regresion: Redes Neuronales y Bosques Aleatorios. Para esto usaremos los datos housing. Estos datos incluyen información sobre precio de la vivienda un determinado distrito de California y algunas estadísticas resumidas sobre ellas basadas en los datos del censo de 1990. Hay que tener en cuenta que los datos no están depurados, por lo que se requieren algunos pasos de preprocesamiento. Las caracteristicas incluidas son:\n","\n","* longitude\n","* latitude\n","* housing_median_age\n","* total_rooms\n","* total_bedrooms\n","* population\n","* households\n","* median_income\n","* median_house_value\n","* ocean_proximity"],"metadata":{"id":"4ADvDunJFRuo"}},{"cell_type":"markdown","source":["## Lectura de datos y pre-procesamiento\n","\n"],"metadata":{"id":"LVx0dxZKGBzy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"37RDbZ4oEgQ3"},"outputs":[],"source":["#Importar librerias\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","source":["#Leer archivo housing.csv\n"],"metadata":{"id":"JpPC_xLNHRHe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Revisión de los datos\n","#Cabecera\n"],"metadata":{"id":"A_2Pa9B9HfpM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Información\n"],"metadata":{"id":"LFnSoM2BhK6g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Eliminar muestras con valores perdidos\n","##"],"metadata":{"id":"NvrrxkaOIGkw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Conversión de variables categoricas\n","##"],"metadata":{"id":"-lsh2wm9I1XC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##  División de los datos para entrenamiento\n","\n","Nuestra variable objetivo es el valor de la vivienda ('median_house_value')."],"metadata":{"id":"lR_d840OKXnz"}},{"cell_type":"code","source":["#Separamos entradas (X) y salidas (y)\n","##"],"metadata":{"id":"Zyra1n18LVtY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dividimos los datos\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"],"metadata":{"id":"s83NZYT4MbfN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vamos a normalizar los datos. Para ello utilizaremos el metodo min_max_scaler"],"metadata":{"id":"4R4UPXSdMt7E"}},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","##"],"metadata":{"id":"eSJeRT0HM0RJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Perceptron Multicapa usando Keras\n","\n","Keras es un API de alto nivel para Deep Learning (DL). Permite construir, entrenar, evaluar y ejecutar varias clases de redes neuronales.\n","\n","Se recomienda consultar las especificaciones técnicas de la librería en el siguiente link.\n","\n","Existen otros APIs para la implementación de técnicas de DL. Sin embargo, Keras ha ganado popularidad por su facilidad de uso, flexibilidad, y portabilidad.\n","\n","TensorFlow incluye la librería Keras, facilitando la lectura y preprocesamiento de datos. En esta práctica usaremos esta librería tk.keras, aunque no usaremos características específicas de TensorFlow. Esta librería se encuentra preinstalada en colab.\n","\n","Otra librería popular es PyTorch. Las versiones recientes de PyTorch y Keras son similares, en parte inspiradas por la facilidad de uso de Scikit-Learn. Por lo anterior, una vez se conoce Keras no debe ser difícil cambiar a PyTorch.\n","\n","Paso 1\n","Vamos a construir una red neuronal multicapa"],"metadata":{"id":"te70gpj8NO1X"}},{"cell_type":"code","source":["# Importacion de librerias\n","##"],"metadata":{"id":"2zS--dkfNPOD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora, vamos a construir la red neuronal multicapa (MLP) empleando el modelo Sequential API de Keras. Este modelo permite crear una pila de capas simples.\n","\n","Entre los tipos de capas que podemos crear se encuentra:\n","\n","\n","1.   Flatten: permite pasar datos matriciales a 1 dimensión. En este proceso se agrega una dimensión a cada muestra con un valor de 1s (para incluir el bias como un peso en el entrenamiento)\n","2.   Dense: capas de neuronas completamente conectada. Entre los parámetros se incluyen el número de neuronas y la función de activación. Los pesos se inicializan de forma aleatoria y el bias se inicializa en 0s. Las funciones de activacion soportadas las puede consultar en este [link](https://keras.io/api/layers/activations/).\n"],"metadata":{"id":"weuieHOUjGTU"}},{"cell_type":"code","source":["#Construccion del MLP\n","##"],"metadata":{"id":"SyRaWyLbRzyr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Nota: cada capa incluye un gran número de parámetros. Por ejemplo, la primera capa oculta tiene 13x1000 pesos que estimar, más 1000 pesos relacionados con el bias. Esto implica que en total debemos entrenar para esta capa 14,000 parámetros. Esto permite una alta flexibilidad para ajustarse a los datos de entrenamiento, pero debido al tamaño del modelo puede tener un sobreajuste.\n","\n","Exploremos un poco las capas del modelo:"],"metadata":{"id":"xV3vPR1NjguX"}},{"cell_type":"code","source":["#Podemos acceder a la lista de capas:\n","##"],"metadata":{"id":"x4pVH2z9j6Ar"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Revisar los pesos y bias de cada capa\n","##\n","\n","#Mostrar los pesos\n","##"],"metadata":{"id":"ZgnAHdv_j9QC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Mostrar biases\n","##"],"metadata":{"id":"Vuia1WlFkFEu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note que la capa se inicializa con pesos aleatorios y bias en 0s. Keras incluye otros métodos de inicialización de\n","los pesos. El tamaño de la primera capa oculta depende del número de entradas, por eso se recomienda incluir este número en la capa inicial.\n","\n","Una vez creado el modelo, se invoca el método compile() que permite especificar:\n","\n","*   La función de perdida: Keras incluye una gran variedad de funciones de perdida. Por ejemplo, diferentes tipos de entropía cruzada para clasificación, tipos de error como MSE y MAE para regresión, entre otros. Consulte las posibles funciones de perdida en este [link](https://keras.io/api/losses/).\n","*   El método de optimización: los optimizadores disponibles se pueden consultar en este [link](https://keras.io/api/optimizers/). El optimizar es el método empleado durante el algoritmo de backpropagation. En esta práctica usaremos SGD (Gradiente Estocástico Descendiente), inicialmente con sus parámetros por defecto (paso de aprendizaje = 0.01).\n","*   La métrica de evaluación: en este caso usaremos  el MSE. Otras métricas disponibles pueden consultarse en el siguiente [link](https://keras.io/api/metrics/).\n"],"metadata":{"id":"SvHOjz86kH7y"}},{"cell_type":"code","source":["#Vamos a compilar el modelo\n","##"],"metadata":{"id":"nVoBHS_TTncE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Una vez compilado, esta listo para ser entrenado\n","#a traves del metodo fit\n","#Le enviamos los datos de entrenamiento, el numero\n","#de epocas, y el set de validacion (opcional)\n","###"],"metadata":{"id":"oTCX-sx0k9dt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Notas:\n","\n","*   En vez de enviar los datos de validación, también puede especificar el porcentaje de datos a usar de validación. Por ejemplo, validation_split=0.1 indicara a Keras que use el 10% de los datos antes de aleatorizarlos para validación\n","*   El método fit() retorna un objeto con la historia del entrenamiento, incluyendo los parámetros entrenados, la lista de épocas con las métricas de desempeño seleccionada. Podemos usar estos datos para graficar la curva de aprendizaje del proceso."],"metadata":{"id":"sRFEf5a8oBhS"}},{"cell_type":"code","source":["#Curva de aprendizaje\n","history_dict = history.history\n","loss_values = history_dict['loss'] # puedes modificar esto\n","val_loss_values = history_dict['val_loss'] # puedes modificar esto\n","epochs = range(1, len(loss_values) + 1) # range of X (no. of epochs)\n","plt.plot(epochs, loss_values, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss_values, 'orange', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"JcU96ffboSvd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vamos a incluir EarlyStopping para evitar el sobreajuste y además a aumentar el número de epocas: permite detener el proceso cuando la función de perdida ya no esta decreciendo. El parametro patience indica el número de epocas a considerar cuando ya no hay una mejora del entrenamiento"],"metadata":{"id":"TkjjUqTvUC0T"}},{"cell_type":"code","source":["#Configurar EarlyStopping\n","es = EarlyStopping(monitor='val_loss',\n","                   mode='min',\n","                   patience=10,\n","                   restore_best_weights = True)"],"metadata":{"id":"z1Z4gOvkUJTs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Entrenamos el modelo\n","#Tomara unos minutos\n","history = model.fit(X_train, y_train,\n","                    validation_data = (X_test, y_test),\n","                    callbacks=[es],\n","                    epochs=100,\n","                    batch_size=50,\n","                    verbose=1)"],"metadata":{"id":"SRfi1nDqUgyQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# specificar las dimensiones\n","fig, axes = plt.subplots(1,2) # 1 row, 2 columns\n","\n","# resultados de entrenamiento\n","axes[0].scatter(x=y_train, y=model.predict(X_train))\n","axes[0].set_xlabel(\"Actual\", fontsize=10)\n","axes[0].set_ylabel(\"Predicted\",  fontsize=10)\n","axes[0].set_title(\"Training\")\n","\n","x = np.linspace(*axes[0].get_xlim())\n","axes[0].plot(x, x, color='red')\n","# resultados de validación\n","axes[1].scatter(x=y_test, y=model.predict(X_test))\n","axes[1].set_xlabel(\"Actual\", fontsize=10)\n","axes[1].set_ylabel(\"Predicted\",  fontsize=10)\n","axes[1].set_title(\"Validation\")\n","\n","x = np.linspace(*axes[1].get_xlim())\n","axes[1].plot(x, x, color='red')\n","\n","\n","fig.tight_layout()\n","plt.show()"],"metadata":{"id":"3DwtEhV1FEJo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["** Realiza las Métricas de error de regresión. **"],"metadata":{"id":"ipzbeLRGGBKM"}},{"cell_type":"code","source":["#Metricas de desempeño\n","from sklearn import metrics\n","\n","pred = model.predict(X_test)\n","\n","print('MAE:', metrics.mean_absolute_error(y_test, pred))\n","print('MSE:', metrics.mean_squared_error(y_test, pred))\n","print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred)))\n","print('R2_score:', metrics.r2_score(y_test, pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hbnwtewmFh3z","outputId":"1a91564a-4a7f-47ba-d0cc-a9f7befcee6c","executionInfo":{"status":"ok","timestamp":1714075439508,"user_tz":300,"elapsed":1560,"user":{"displayName":"Maria Constanza Torres Madronero","userId":"13666158650983973700"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["192/192 [==============================] - 1s 4ms/step\n","MAE: 63379.46696892843\n","MSE: 6963769341.709494\n","RMSE: 83449.20216340893\n","R2_score: 0.48773252202176165\n"]}]},{"cell_type":"markdown","source":["# ¡Gran trabajo!"],"metadata":{"id":"Mx0JGSCDGTsN"}}]}